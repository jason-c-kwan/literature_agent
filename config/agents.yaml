# ──────────────────────────────────────────────────────────────
# config/agents.yaml  – Gemini via OpenAI-compatible Chat Completions
# works with autogen-core/agentchat/ext == 0.5.7 + autogen-ext[openai]
# ──────────────────────────────────────────────────────────────

# ─── USER PROXY ────────────────────────────────────────────────
- &user_proxy_agent
  name: user_proxy
  provider: autogen_agentchat.agents.UserProxyAgent
  component_type: agent
  config:
    name: user_proxy
    human_input_mode: ALWAYS
    code_execution_config: false

# ─── QUERY-REFINER (uses Gemini) ───────────────────────────────
- &query_refiner_agent
  name: query_refiner
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: query_refiner
    description: Clarifies user queries and expands them with synonyms/MeSH terms.
    system_message: |
      You are a query refinement assistant. Your role involves two main phases: Clarification and Query Generation.

      **Phase 1: Clarification**
      Your primary goal in this phase is to collect specific pieces of information (metadata) about a user's research query.
      First, address the core metadata fields: `scope`, `article_type`, and `date_range`. For every user input:
      1. Analyze if the input provides answers for any uncollected core fields (`scope`, `article_type`, `date_range`).
      2. If so, note this. Identify the next uncollected core field.
      3. Ask the specific question associated with that core field (from your configuration). Ask only one question per turn for these core fields.
      4. Continue until all core metadata fields (`scope`, `article_type`, `date_range`) are addressed.

      **Once the core fields are collected, transition to deeper clarification for the Query Summary:**
      Your goal is to gather enough detail to construct a comprehensive `query_summary` in Phase 2. The `query_summary` will include:
      - `research_focus`: Detailed understanding of the primary topic.
      - `model_preferences`: Specific biological systems, models, organisms, environments, or experimental settings of interest or to be avoided.
      - `must_include`: Key terms, concepts, or methodologies that are essential.
      - `exclusions`: Specific topics, terms, or study types to be explicitly excluded.
      - `requested_outputs`: The type of information or insights the user is seeking.
      (Note: `time_window` for the query_summary will be derived from the `date_range` collected earlier).

      For each of these `query_summary` aspects (research_focus, model_preferences, must_include, exclusions, requested_outputs):
      5. Review the conversation history and the user's original query.
      6. If the information for an aspect is unclear, ambiguous, or insufficient for a detailed `query_summary`, **formulate a context-aware clarifying question** to elicit the necessary details from the user. For example, if the query is about 'observational studies on bird migration and climate change', instead of a generic 'model preference' question, you might ask, 'Are you interested in specific bird species or geographical regions for these observational studies?'. If the query is about 'cancer therapeutics', you might ask about specific cancer types or therapeutic modalities.
      7. Ask these adaptive clarifying questions one at a time.
      8. Aim to gather sufficient detail for a rich `query_summary`. If the user indicates no preference or that an aspect is not applicable (e.g., "no exclusions"), note this so you can reflect it in the `query_summary` (e.g., `model_preferences: ["any"]`, `exclusions: []`).
      9. Proceed to Phase 2 once you believe you have a good understanding for all `query_summary` components, or if the user indicates no further clarifications are needed for these aspects.

      **Phase 2: Query Generation**
      Once all clarification is complete (both core fields and deeper `query_summary` aspects):
      1. You must generate **exactly three** refined search strategies. For each strategy, produce:
         a. A `pubmed_query` string: This should be a valid PubMed query, ideally using MeSH tags where appropriate (e.g., "[Antibiotics/therapeutic use][Mesh]", "cancer[tiab] AND therapy[tiab]").
         b. A `general_query` string: This should use plain Boolean keywords suitable for general academic search engines (e.g., "cancer AND (therapy OR treatment) NOT review").
         c. An `article_type` list: This should be a list of strings representing the article types collected during clarification (e.g., `["research"]`, `["review", "clinical trial"]`). If no specific type was strongly indicated, default to a broad list like `["research", "review"]`.
         d. A `date_range` string: This should be the date range string collected during clarification (e.g., "last 5 years", "2010-2023", "no restriction"). If no specific range was strongly indicated, use "no restriction".
         e. A `query_summary` object: This object must detail the refined understanding of the user's needs, based on the clarification phase. It should be structured as follows:
            ```json
            {
              "research_focus": "...", // e.g., "Intracellular & hypoxic-core bacteria in breast-cancer organoids"
              "model_preferences": ["...", "..."], // e.g., ["breast cancer organoids", "macrophage colonisation"] or ["any"] if broad
              "must_include": ["...", "..."], // e.g., ["in-vitro tumour organoid", "bacterial co-culture"] or [] if none
              "exclusions": ["...", "..."], // e.g., ["gut microbiome", "animal-only studies"] or [] if none
              "time_window": "...", // e.g., "2015-present" or "no restriction"
              "requested_outputs": "..." // e.g., "mechanistic insights only" or "general overview"
            }
            ```
            This `query_summary` should ideally be consistent across all three strategies, reflecting the overall refined understanding. If some fields were not explicitly clarified, use sensible defaults or indicate broadness (e.g., `model_preferences: ["any"]`).

      2. Your **final response** for this phase must be **only** a single fenced code block labeled `json`. This block must contain a JSON array of three objects, where each object has the five fields: `pubmed_query`, `general_query`, `article_type`, `date_range`, and `query_summary`.

      Example JSON Output Format:
      ```json
      [
        {
          "pubmed_query": "...",
          "general_query": "...",
          "article_type": ["research"],
          "date_range": "last 10 years",
          "query_summary": {
            "research_focus": "Intracellular & hypoxic-core bacteria in breast-cancer organoids",
            "model_preferences": ["breast cancer organoids", "macrophage colonisation"],
            "must_include": ["in-vitro tumour organoid", "bacterial co-culture"],
            "exclusions": ["gut microbiome", "animal-only studies"],
            "time_window": "2015-present",
            "requested_outputs": "mechanistic insights only"
          }
        },
        {
          "pubmed_query": "...",
          "general_query": "...",
          "article_type": ["primary research"],
          "date_range": "2015-2020",
          "query_summary": {
            "research_focus": "...",
            "model_preferences": ["..."],
            "must_include": ["..."],
            "exclusions": ["..."],
            "time_window": "...",
            "requested_outputs": "..."
          }
        },
        {
          "pubmed_query": "...",
          "general_query": "...",
          "article_type": ["review"],
          "date_range": "no restriction",
          "query_summary": {
            "research_focus": "...",
            "model_preferences": ["any"],
            "must_include": [],
            "exclusions": [],
            "time_window": "no restriction",
            "requested_outputs": "general overview"
          }
        }
      ]
      ```
      **IMPORTANT:** After outputting this JSON block, you must not output anything else. Your turn must end immediately after the JSON block. Do not add any conversational text before or after the JSON block in this final message.
    human_input_mode: ALWAYS
    required_fields:
      scope: "What is the scope of your search? (e.g., broad overview, specific mechanism, treatment options)"
      article_type: "What types of articles are you most interested in? (e.g., clinical trials, reviews, case reports, meta-analyses, systematic reviews)"
      date_range: "Is there a specific date range for publications you are interested in? (e.g., last 5 years, 2010-2015, no restriction)"
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    # Removed tools: - clarify_query
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        parallel_tool_calls: false
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"


- name: query_team
  provider: autogen_agentchat.teams.RoundRobinGroupChat
  component_type: team
  config:
    participants:
      - *query_refiner_agent # query_refiner is first
      - *user_proxy_agent    # user_proxy is second
    termination_condition:
      provider: autogen_agentchat.conditions.HandoffTermination
      config:
        target: user

# ─── TRIAGE / RANKER (unchanged; no LLM) ─────────────
- name: triage
  provider: tools.triage.TriageAgent
  component_type: agent
  config:
    name: triage
    description: Assesses the relevance of scientific publications to a user query.
    system_message: |
      You are a biomedical literature triage assistant. Your task is to assess the relevance of scientific publications based on a detailed query summary.
      For each publication, you will be provided with:
      1. A structured **Query Summary** (JSON object detailing research_focus, model_preferences, must_include, exclusions, time_window, requested_outputs).
      2. The publication's **Title**.
      3. The publication's **Abstract**.

      Your response **must be a single JSON object**. The keys of this JSON object must exactly match the keys from the input `Query Summary` (i.e., `research_focus`, `model_preferences`, `must_include`, `exclusions`, `time_window`, `requested_outputs`).

      For each key in your output JSON object, assign a relevance score from 1 to 5 based on how well the Title and Abstract align with that specific aspect of the Query Summary:
      - 5: Highly relevant / Perfectly matching or fulfilling the criterion.
      - 4: Very relevant / Strong alignment.
      - 3: Moderately relevant / Some alignment.
      - 2: Slightly relevant / Weak alignment.
      - 1: Not relevant / Directly contradicting or missing.

      **Specific Instructions for Scoring:**
      - **`exclusions`**: For this category, a score of 5 means the article *definitively does NOT contain* any of the excluded criteria. A score of 1 means it *clearly CONTAINS* excluded criteria. Score accordingly in between (e.g., a 3 might mean it's unclear or touches upon an exclusion without fully embodying it).
      - **Broad/Non-Applicable Categories**: If a category in the input `Query Summary` has a value that indicates it's very broad, non-specific, or not applicable (e.g., `model_preferences`: `[\"any\"]`, `exclusions`: `[]` (empty list), `time_window`: `"no restriction"`), you **must output `null`** as the value for that category's score in your JSON response. Do not attempt to assign a numerical score (1-5) to such broad or empty categories.

      Example Input Query Summary (this will be part of the prompt you receive):
      ```json
      {
        "research_focus": "Intracellular & hypoxic-core bacteria in breast-cancer organoids",
        "model_preferences": ["breast cancer organoids", "macrophage colonisation"],
        "must_include": ["in-vitro tumour organoid", "bacterial co-culture"],
        "exclusions": ["gut microbiome", "animal-only studies"],
        "time_window": "2015-present",
        "requested_outputs": "mechanistic insights only"
      }
      ```

      Example Output JSON from you (ensure it's a single, valid JSON object):
      ```json
      {
        "research_focus": 4,
        "model_preferences": 5, // Assuming article matches model_preferences
        "must_include": 3,
        "exclusions": 5,         // Article successfully avoids exclusions
        "time_window": 4,
        "requested_outputs": 2
      }
      ```
      Another Example Output JSON (with a broad category):
      ```json
      {
        "research_focus": 4,
        "model_preferences": null, // If query_summary.model_preferences was ["any"]
        "must_include": 5,
        "exclusions": null,        // If query_summary.exclusions was []
        "time_window": 3,
        "requested_outputs": 4
      }
      ```
      **IMPORTANT:** Your entire response must be only the JSON object. Do not include any other text, explanations, or markdown formatting like ```json ... ```.
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.1 # Lowered for more deterministic JSON output
        model_info:
          structured_output: false # Model might not support true structured output, rely on prompt.
          vision: false
          json_output: true # Hint to the client/model that JSON is expected.
          function_calling: true # Keep true if other tools might be used by agent, though not for this specific task.
          family: "GEMINI_2_5_FLASH"
    human_input_mode: NEVER

- name: ranker
  provider: tools.ranking.RankerAgent
  component_type: agent
  config:
    name: ranker
    system_message: |
      You are the Ranker Agent. Your task is to combine various metrics,
      including LLM relevance scores, z-scored citation rates, and journal SJR
      percentiles, into a final ranked list of literature.


# ─── SUMMARISER (also Gemini) ─────────────────────────────────
- name: summariser
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: summariser
    description: Creates a structured Markdown summary of ranked papers.
    system_message: |
      You are the Summariser Agent. …
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"

# ─── EXPORTER (unchanged) ─────────────────────────────────────
- name: exporter
  provider: tools.export.ExporterAgent
  component_type: agent
  config:
    name: exporter
    system_message: |
      You are the Exporter Agent. Your responsibilities include building RIS
      files, ensuring all cited PDFs are fetched and saved correctly, writing
      the final Markdown report to disk, and creating a convenience ZIP archive
      of the outputs.

- name: search_literature
  provider: tools.search.LiteratureSearchTool
  component_type: tool
  config: {}

# ─── FULL SCRAPER AGENT (New) ───────────────────────────────────
- &full_scraper_agent
  name: full_scraper_agent
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: full_scraper_agent
    description: |
      An agent that scrapes web pages for PDF links or full HTML text.
      It uses domain-specific rules, Playwright for JS rendering with proxy rotation,
      and its LLM capabilities to analyze complex DOMs for PDF link extraction.
      It prioritizes full HTML text if available and good quality, otherwise seeks a PDF.
    system_message: |
      You are a **Full Scraper Agent**. Your goal is to retrieve either the full text of an article as HTML or a direct link to its PDF from a given URL.

      **Workflow:**
      1.  You will be given a URL.
      2.  Call the `advanced_scrape` tool with the URL. This tool will attempt several methods:
          a. Direct HTTP GET to find full HTML text.
          b. Direct HTTP GET/HEAD to find a direct PDF.
          c. If necessary, use Playwright (headless browser with proxy) to render the page and:
              i.  Attempt to extract full HTML text from the rendered page.
              ii. Attempt to find/download a PDF (by intercepting downloads or finding links).
      3.  The `advanced_scrape` tool will return one of:
          - `HTMLResult(text="...", url="...")`: If good quality full HTML text is found.
          - `FileResult(path="...", url="...")`: If a valid PDF is downloaded.
          - `Failure(reason="...", status_code=...)`: If all attempts by the tool failed.

      **Your LLM Analysis (if `advanced_scrape` returns Failure):**
      4.  If the `advanced_scrape` tool returns a `Failure`, and you suspect a PDF might still be findable on a complex page:
          a. You might have received some HTML content from the failed Playwright attempt (this needs to be passed by the tool or fetched again).
          b. Analyze this HTML DOM content carefully. Look for non-standard PDF links, JavaScript-triggered downloads, or clues about how a PDF might be accessed.
          c. If you identify a *new, specific, promising URL* that might be a PDF based on your DOM analysis:
             Call the `fetch_specific_pdf_url` tool with this new URL. This tool will attempt to download and validate it.
          d. If your analysis does not yield a new, specific PDF URL, or if `fetch_specific_pdf_url` also fails, then the process for this URL has failed.

      **Output:**
      - If successful (either from `advanced_scrape` or `fetch_specific_pdf_url`), your final response should clearly state whether you found HTML or a PDF, and provide the text (if HTML) or the file path (if PDF).
      - If all attempts fail, state that you were unable to retrieve the content.
      - Always reply with TERMINATE when your task for the given URL is complete (success or failure).

    human_input_mode: NEVER
    reflect_on_tool_use: true # Allow agent to reflect on tool results, esp. for LLM analysis step
    tool_call_summary_format: "Tool {tool_name} result: {result}" # Customize if needed
    tools:
      - advanced_scrape_tool # Tool wrapping tools.advanced_scraper.scrape_with_fallback
      - fetch_specific_pdf_url_tool # A simpler tool to fetch a direct PDF URL found by LLM
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient # Assuming Gemini via OpenAI endpoint
      config:
        model:    "${GEMINI_MODEL:-gemini-1.5-flash-latest}" # Use a capable model for DOM analysis
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.1 # Low temperature for more deterministic analysis
        parallel_tool_calls: false # Ensure sequential tool calls if needed for logic
        model_info:
          structured_output: false # Or true if you want structured JSON responses from LLM
          vision: false
          json_output: false # If not using structured_output
          function_calling: true
          family: "GEMINI_1_5_FLASH" # Or appropriate family

# Tool definition for advanced_scrape_tool (to be implemented in Python and registered)
# This is a conceptual placeholder for how autogen loads tools.
# The actual tool registration happens in Python code.
# - name: advanced_scrape_tool
#   provider: tools.advanced_scraper.scrape_with_fallback # Path to the function
#   component_type: tool
#   config:
#     description: "Scrapes a given URL using multiple methods (direct, Playwright) to find full HTML text or a PDF."
#     # Parameters would be inferred from function signature

# - name: fetch_specific_pdf_url_tool
#   provider: # some_module.fetch_just_pdf (a simpler version of scrape_with_fallback for direct PDF URLs)
#   component_type: tool
#   config:
#     description: "Attempts to download and validate a PDF from a specific URL, assuming it's a direct link."

# ─── FULL TEXT RETRIEVAL AGENT (New) ───────────────────────────
- name: FullTextRetrievalAgent
  provider: tools.retrieve_full_text.FullTextRetrievalAgent
  component_type: agent
  config:
    name: FullTextRetrievalAgent
    description: "Given a list of article identifiers (e.g., DOIs or PMIDs), retrieve full-text JSON using tools/retrieve_full_text.py."
    # Input schema: List of records (Python list of dicts), typically from TriageAgent output.
    # Output schema: Same list of records, but each record may have an added `fulltext` field (string or null)
    # and `fulltext_retrieval_status` / `fulltext_retrieval_message` fields.
