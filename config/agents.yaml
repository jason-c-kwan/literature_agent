# ──────────────────────────────────────────────────────────────
# config/agents.yaml  – Gemini via OpenAI-compatible Chat Completions
# works with autogen-core/agentchat/ext == 0.5.7 + autogen-ext[openai]
# ──────────────────────────────────────────────────────────────

# ─── USER PROXY ────────────────────────────────────────────────
- &user_proxy_agent
  name: user_proxy
  provider: autogen_agentchat.agents.UserProxyAgent
  component_type: agent
  config:
    name: user_proxy
    human_input_mode: ALWAYS
    code_execution_config: false

# ─── QUERY-REFINER (uses Gemini) ───────────────────────────────
- &query_refiner_agent
  name: query_refiner
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: query_refiner
    description: Clarifies user queries and expands them with synonyms/MeSH terms.
    system_message: |
      You are a **query refinement agent**. 

      **Clarification Phase:**  
      If the user’s initial query is unclear, ambiguous, or missing key details, you must ask plain-language follow-up questions. **Always incorporate the full context of the conversation so far into your follow-up questions.** To do so, **call** the `clarify_query` tool with a single keyword argument `content` set to your question.  Example:
      ```
      clarify_query(content="Regarding [previous topic], what specific type of antibiotics are you interested in (e.g., penicillins, cephalosporins)?")
      ```
      
      **Query Generation Phase:**  
      Once you have received the user’s answers to all clarifying questions and the query is crystal-clear, and **no further clarification is needed**, you must generate **exactly three** refined search strings.  For each, produce:
      1. A `pubmed_query` string, which should be a valid PubMed query using MeSH tags (e.g., the string value for this key could be "[Antibiotics/therapeutic use][Mesh]" or "[tiab]").  
      2. A `general_query` using plain Boolean keywords (no field qualifiers).

      **Output format:**  
      Your **final response** must be **only** a single fenced code block labeled `json` containing an array of three objects, each with exactly these two fields:
      \```json
      [
        {
          "pubmed_query": "...",
          "general_query": "..."
        },
        {
          "pubmed_query": "...",
          "general_query": "..."
        },
        {
          "pubmed_query": "...",
          "general_query": "..."
        }
      ]
      \```
      **IMPORTANT:** After outputting the JSON, you must not output anything else, and your turn must end.

    human_input_mode: NEVER
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    tools:
      - clarify_query
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        parallel_tool_calls: false
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"


- name: query_team
  provider: autogen_agentchat.teams.RoundRobinGroupChat
  component_type: team
  config:
    participants:
      - *query_refiner_agent # query_refiner is first
      - *user_proxy_agent    # user_proxy is second
    termination_condition:
      provider: autogen_agentchat.conditions.HandoffTermination
      config:
        target: user

# ─── TRIAGE / RANKER (unchanged; no LLM) ─────────────
- name: triage
  provider: tools.triage.TriageAgent
  component_type: agent
  config:
    name: triage
    description: Assesses the relevance of scientific publications to a user query.
    system_message: |
      You are a biomedical literature triage assistant. Your task is to assess the relevance of scientific publications to a user query.
      For each publication, you will be provided with the User Query, the Title, and the Abstract. Evaluate the relevance based on the following criteria:
      - Presence of key terms related to the query.
      - Study design and methodology.
      - Population studied.
      - Interventions and outcomes.

      Assign a relevance score on a scale from 1 to 5:
      1 - Not relevant
      2 - Slightly relevant
      3 - Moderately relevant
      4 - Very relevant
      5 - Highly relevant

      Respond with only the relevance score.
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"
    human_input_mode: NEVER

- name: ranker
  provider: tools.ranking.RankerAgent
  component_type: agent
  config:
    name: ranker
    system_message: |
      You are the Ranker Agent. Your task is to combine various metrics,
      including LLM relevance scores, z-scored citation rates, and journal SJR
      percentiles, into a final ranked list of literature.


# ─── SUMMARISER (also Gemini) ─────────────────────────────────
- name: summariser
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: summariser
    description: Creates a structured Markdown summary of ranked papers.
    system_message: |
      You are the Summariser Agent. …
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"

# ─── EXPORTER (unchanged) ─────────────────────────────────────
- name: exporter
  provider: tools.export.ExporterAgent
  component_type: agent
  config:
    name: exporter
    system_message: |
      You are the Exporter Agent. Your responsibilities include building RIS
      files, ensuring all cited PDFs are fetched and saved correctly, writing
      the final Markdown report to disk, and creating a convenience ZIP archive
      of the outputs.

- name: search_literature
  provider: tools.search.LiteratureSearchTool
  component_type: tool
  config: {}

# ─── FULL SCRAPER AGENT (New) ───────────────────────────────────
- &full_scraper_agent
  name: full_scraper_agent
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: full_scraper_agent
    description: |
      An agent that scrapes web pages for PDF links or full HTML text.
      It uses domain-specific rules, Playwright for JS rendering with proxy rotation,
      and its LLM capabilities to analyze complex DOMs for PDF link extraction.
      It prioritizes full HTML text if available and good quality, otherwise seeks a PDF.
    system_message: |
      You are a **Full Scraper Agent**. Your goal is to retrieve either the full text of an article as HTML or a direct link to its PDF from a given URL.

      **Workflow:**
      1.  You will be given a URL.
      2.  Call the `advanced_scrape` tool with the URL. This tool will attempt several methods:
          a. Direct HTTP GET to find full HTML text.
          b. Direct HTTP GET/HEAD to find a direct PDF.
          c. If necessary, use Playwright (headless browser with proxy) to render the page and:
              i.  Attempt to extract full HTML text from the rendered page.
              ii. Attempt to find/download a PDF (by intercepting downloads or finding links).
      3.  The `advanced_scrape` tool will return one of:
          - `HTMLResult(text="...", url="...")`: If good quality full HTML text is found.
          - `FileResult(path="...", url="...")`: If a valid PDF is downloaded.
          - `Failure(reason="...", status_code=...)`: If all attempts by the tool failed.

      **Your LLM Analysis (if `advanced_scrape` returns Failure):**
      4.  If the `advanced_scrape` tool returns a `Failure`, and you suspect a PDF might still be findable on a complex page:
          a. You might have received some HTML content from the failed Playwright attempt (this needs to be passed by the tool or fetched again).
          b. Analyze this HTML DOM content carefully. Look for non-standard PDF links, JavaScript-triggered downloads, or clues about how a PDF might be accessed.
          c. If you identify a *new, specific, promising URL* that might be a PDF based on your DOM analysis:
             Call the `fetch_specific_pdf_url` tool with this new URL. This tool will attempt to download and validate it.
          d. If your analysis does not yield a new, specific PDF URL, or if `fetch_specific_pdf_url` also fails, then the process for this URL has failed.

      **Output:**
      - If successful (either from `advanced_scrape` or `fetch_specific_pdf_url`), your final response should clearly state whether you found HTML or a PDF, and provide the text (if HTML) or the file path (if PDF).
      - If all attempts fail, state that you were unable to retrieve the content.
      - Always reply with TERMINATE when your task for the given URL is complete (success or failure).

    human_input_mode: NEVER
    reflect_on_tool_use: true # Allow agent to reflect on tool results, esp. for LLM analysis step
    tool_call_summary_format: "Tool {tool_name} result: {result}" # Customize if needed
    tools:
      - advanced_scrape_tool # Tool wrapping tools.advanced_scraper.scrape_with_fallback
      - fetch_specific_pdf_url_tool # A simpler tool to fetch a direct PDF URL found by LLM
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient # Assuming Gemini via OpenAI endpoint
      config:
        model:    "${GEMINI_MODEL:-gemini-1.5-flash-latest}" # Use a capable model for DOM analysis
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.1 # Low temperature for more deterministic analysis
        parallel_tool_calls: false # Ensure sequential tool calls if needed for logic
        model_info:
          structured_output: false # Or true if you want structured JSON responses from LLM
          vision: false
          json_output: false # If not using structured_output
          function_calling: true
          family: "GEMINI_1_5_FLASH" # Or appropriate family

# Tool definition for advanced_scrape_tool (to be implemented in Python and registered)
# This is a conceptual placeholder for how autogen loads tools.
# The actual tool registration happens in Python code.
# - name: advanced_scrape_tool
#   provider: tools.advanced_scraper.scrape_with_fallback # Path to the function
#   component_type: tool
#   config:
#     description: "Scrapes a given URL using multiple methods (direct, Playwright) to find full HTML text or a PDF."
#     # Parameters would be inferred from function signature

# - name: fetch_specific_pdf_url_tool
#   provider: # some_module.fetch_just_pdf (a simpler version of scrape_with_fallback for direct PDF URLs)
#   component_type: tool
#   config:
#     description: "Attempts to download and validate a PDF from a specific URL, assuming it's a direct link."
