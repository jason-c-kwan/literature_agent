# ──────────────────────────────────────────────────────────────
# config/agents.yaml  – Gemini via OpenAI-compatible Chat Completions
# works with autogen-core/agentchat/ext == 0.5.7 + autogen-ext[openai]
# ──────────────────────────────────────────────────────────────

# ─── USER PROXY ────────────────────────────────────────────────
- &user_proxy_agent
  name: user_proxy
  provider: autogen_agentchat.agents.UserProxyAgent
  component_type: agent
  config:
    name: user_proxy
    human_input_mode: ALWAYS
    code_execution_config: false

# ─── QUERY-REFINER (uses Gemini) ───────────────────────────────
- &query_refiner_agent
  name: query_refiner
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: query_refiner
    description: Clarifies user queries and expands them with synonyms/MeSH terms.
    system_message: |
      You are a query refinement assistant. Your goal is to collect specific pieces of information (metadata) about a user's research query.
      The required fields you need to collect are defined in your configuration (e.g., purpose, scope, audience, article_type, date_range, open_access, output_format).
      For every user input (including their initial query and any subsequent responses):
      1. First, carefully analyze the user's input to see if it already provides a clear answer for any of the required fields that you haven't collected yet.
      2. If you find an answer for one or more fields from the user's input, internally note this information.
      3. Then, identify the *next single required field* for which you don't yet have information.
      4. Ask the specific question associated with that field (using the prompt text defined for that field in your configuration). Ask only one question per turn.
      5. If all required fields have been addressed (either from the user's input or your prior questions):
         a. Summarize all the collected information clearly.
         b. Based on the original query and all collected metadata, formulate a concise and effective set of keywords or a refined search query suitable for academic search engines. Present this as "Refined Search Terms: [your terms/query]".
         c. State that you will now proceed with the research using these refined terms.
      Do not run any search or perform other actions until all required fields have been collected, confirmed, and refined search terms generated.
    human_input_mode: ALWAYS
    required_fields:
      purpose: "What is the primary purpose of your research? (e.g., writing a review, clinical decision support, grant proposal)"
      scope: "What is the scope of your search? (e.g., broad overview, specific mechanism, treatment options)"
      audience: "Who is the intended audience for this research? (e.g., clinicians, researchers, patients)"
      article_type: "What types of articles are you most interested in? (e.g., clinical trials, reviews, case reports, meta-analyses, systematic reviews)"
      date_range: "Is there a specific date range for publications you are interested in? (e.g., last 5 years, 2010-2015, no restriction)"
      open_access: "Do you require only open access articles? (yes/no)"
      output_format: "What is your preferred output format for the results? (e.g., brief summary, detailed report, list of DOIs)"
      # keywords: "Please provide a few main keywords or phrases that best describe your topic." # Removed
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    # Removed tools: - clarify_query
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        parallel_tool_calls: false
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"


- name: query_team
  provider: autogen_agentchat.teams.RoundRobinGroupChat
  component_type: team
  config:
    participants:
      - *query_refiner_agent # query_refiner is first
      - *user_proxy_agent    # user_proxy is second
    termination_condition:
      provider: autogen_agentchat.conditions.HandoffTermination
      config:
        target: user

# ─── TRIAGE / RANKER (unchanged; no LLM) ─────────────
- name: triage
  provider: tools.triage.TriageAgent
  component_type: agent
  config:
    name: triage
    description: Assesses the relevance of scientific publications to a user query.
    system_message: |
      You are a biomedical literature triage assistant. Your task is to assess the relevance of scientific publications to a user query.
      For each publication, you will be provided with the User Query, the Title, and the Abstract. Evaluate the relevance based on the following criteria:
      - Presence of key terms related to the query.
      - Study design and methodology.
      - Population studied.
      - Interventions and outcomes.

      Assign a relevance score on a scale from 1 to 5:
      1 - Not relevant
      2 - Slightly relevant
      3 - Moderately relevant
      4 - Very relevant
      5 - Highly relevant

      Respond with only the relevance score.
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"
    human_input_mode: NEVER

- name: ranker
  provider: tools.ranking.RankerAgent
  component_type: agent
  config:
    name: ranker
    system_message: |
      You are the Ranker Agent. Your task is to combine various metrics,
      including LLM relevance scores, z-scored citation rates, and journal SJR
      percentiles, into a final ranked list of literature.


# ─── SUMMARISER (also Gemini) ─────────────────────────────────
- name: summariser
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: summariser
    description: Creates a structured Markdown summary of ranked papers.
    system_message: |
      You are the Summariser Agent. …
    reflect_on_tool_use: false
    tool_call_summary_format: "{result}"
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient
      config:
        model:    "${GEMINI_MODEL:-gemini-2.5-flash-preview-05-20}"
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.2
        model_info:
          structured_output: false
          vision: false
          json_output: true
          function_calling: true
          family: "GEMINI_2_5_FLASH"

# ─── EXPORTER (unchanged) ─────────────────────────────────────
- name: exporter
  provider: tools.export.ExporterAgent
  component_type: agent
  config:
    name: exporter
    system_message: |
      You are the Exporter Agent. Your responsibilities include building RIS
      files, ensuring all cited PDFs are fetched and saved correctly, writing
      the final Markdown report to disk, and creating a convenience ZIP archive
      of the outputs.

- name: search_literature
  provider: tools.search.LiteratureSearchTool
  component_type: tool
  config: {}

# ─── FULL SCRAPER AGENT (New) ───────────────────────────────────
- &full_scraper_agent
  name: full_scraper_agent
  provider: autogen_agentchat.agents.AssistantAgent
  component_type: agent
  config:
    name: full_scraper_agent
    description: |
      An agent that scrapes web pages for PDF links or full HTML text.
      It uses domain-specific rules, Playwright for JS rendering with proxy rotation,
      and its LLM capabilities to analyze complex DOMs for PDF link extraction.
      It prioritizes full HTML text if available and good quality, otherwise seeks a PDF.
    system_message: |
      You are a **Full Scraper Agent**. Your goal is to retrieve either the full text of an article as HTML or a direct link to its PDF from a given URL.

      **Workflow:**
      1.  You will be given a URL.
      2.  Call the `advanced_scrape` tool with the URL. This tool will attempt several methods:
          a. Direct HTTP GET to find full HTML text.
          b. Direct HTTP GET/HEAD to find a direct PDF.
          c. If necessary, use Playwright (headless browser with proxy) to render the page and:
              i.  Attempt to extract full HTML text from the rendered page.
              ii. Attempt to find/download a PDF (by intercepting downloads or finding links).
      3.  The `advanced_scrape` tool will return one of:
          - `HTMLResult(text="...", url="...")`: If good quality full HTML text is found.
          - `FileResult(path="...", url="...")`: If a valid PDF is downloaded.
          - `Failure(reason="...", status_code=...)`: If all attempts by the tool failed.

      **Your LLM Analysis (if `advanced_scrape` returns Failure):**
      4.  If the `advanced_scrape` tool returns a `Failure`, and you suspect a PDF might still be findable on a complex page:
          a. You might have received some HTML content from the failed Playwright attempt (this needs to be passed by the tool or fetched again).
          b. Analyze this HTML DOM content carefully. Look for non-standard PDF links, JavaScript-triggered downloads, or clues about how a PDF might be accessed.
          c. If you identify a *new, specific, promising URL* that might be a PDF based on your DOM analysis:
             Call the `fetch_specific_pdf_url` tool with this new URL. This tool will attempt to download and validate it.
          d. If your analysis does not yield a new, specific PDF URL, or if `fetch_specific_pdf_url` also fails, then the process for this URL has failed.

      **Output:**
      - If successful (either from `advanced_scrape` or `fetch_specific_pdf_url`), your final response should clearly state whether you found HTML or a PDF, and provide the text (if HTML) or the file path (if PDF).
      - If all attempts fail, state that you were unable to retrieve the content.
      - Always reply with TERMINATE when your task for the given URL is complete (success or failure).

    human_input_mode: NEVER
    reflect_on_tool_use: true # Allow agent to reflect on tool results, esp. for LLM analysis step
    tool_call_summary_format: "Tool {tool_name} result: {result}" # Customize if needed
    tools:
      - advanced_scrape_tool # Tool wrapping tools.advanced_scraper.scrape_with_fallback
      - fetch_specific_pdf_url_tool # A simpler tool to fetch a direct PDF URL found by LLM
    model_client:
      provider: autogen_ext.models.openai.OpenAIChatCompletionClient # Assuming Gemini via OpenAI endpoint
      config:
        model:    "${GEMINI_MODEL:-gemini-1.5-flash-latest}" # Use a capable model for DOM analysis
        base_url: "${OPENAI_API_BASE}"
        api_key:  "${OPENAI_API_KEY}"
        temperature: 0.1 # Low temperature for more deterministic analysis
        parallel_tool_calls: false # Ensure sequential tool calls if needed for logic
        model_info:
          structured_output: false # Or true if you want structured JSON responses from LLM
          vision: false
          json_output: false # If not using structured_output
          function_calling: true
          family: "GEMINI_1_5_FLASH" # Or appropriate family

# Tool definition for advanced_scrape_tool (to be implemented in Python and registered)
# This is a conceptual placeholder for how autogen loads tools.
# The actual tool registration happens in Python code.
# - name: advanced_scrape_tool
#   provider: tools.advanced_scraper.scrape_with_fallback # Path to the function
#   component_type: tool
#   config:
#     description: "Scrapes a given URL using multiple methods (direct, Playwright) to find full HTML text or a PDF."
#     # Parameters would be inferred from function signature

# - name: fetch_specific_pdf_url_tool
#   provider: # some_module.fetch_just_pdf (a simpler version of scrape_with_fallback for direct PDF URLs)
#   component_type: tool
#   config:
#     description: "Attempts to download and validate a PDF from a specific URL, assuming it's a direct link."

# ─── FULL TEXT RETRIEVAL AGENT (New) ───────────────────────────
- name: FullTextRetrievalAgent
  provider: tools.retrieve_full_text.FullTextRetrievalAgent
  component_type: agent
  config:
    name: FullTextRetrievalAgent
    description: "Given a list of article identifiers (e.g., DOIs or PMIDs), retrieve full-text JSON using tools/retrieve_full_text.py."
    # Input schema: List of records (Python list of dicts), typically from TriageAgent output.
    # Output schema: Same list of records, but each record may have an added `fulltext` field (string or null)
    # and `fulltext_retrieval_status` / `fulltext_retrieval_message` fields.
